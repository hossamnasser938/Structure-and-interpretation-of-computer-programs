# 3.4 Concurrency: Time Is of the Essence

- Introducing asssignment into our language enabled us to builde computational objects with local state to model real objects in the world. This, sometimes, helps us build more modular peices than we would if we do not have local state. But this comes with a price.

- Assignment forced us to include time in our computational models. Before introducing assignment, an expression's value depends only on the expression itself. After introducing assignment, an expression's value depends on the expression as well as the time at which the expression is being evaluated.

```
(withdraw 25)
75

(withdraw 25)
50
```

- We can go further in modeling real objects. Real objects often behave concurrently not sequentially. So we can build programs that execute concurrently. This will have 2 benefits:
  - Speedup, since performing many tasks at a time would be much faster than performing ony one task at a time.
  - Even if the programs will be executed sequentially, designing programs that run concurrently will force us to build timeless programs which will result in building modular programs.

## 3.4.1 The Nature of Time in Concurrent Systems

- Time in computation is different from time in real life.

- In real life, an event can be defined to be happening in a given moment of time and that's usfficient. We can say that Event `A` happened at 19th of April 2023 at 06:00:00 pm. This means that an event can be defined in terms of time independently.

- This is not the case for time in computation. Time in computation is **an oerdering imposed on events**. For events `A` and `B`, either `A` happens before `B`, `A` happens after `B`, or `A` and `B` happends simultaneously. We usually do not care about the timing but the ordering of events.

- These different orderings is not a problem when dealing with sequential programs but for concurrent programs it is problematic.

- Suppose that `Paul` and `Peter` shares the same account. The account starting `balance` is `100`. `Paul` withdraws `10` and `Peter` withdraws `25`. Then the `balance` sequence values might be `100` => `90` => `65` or `100` => `75` => `65`. This is not a problem for sequential programs. But suppose that a distributed banking system with remote machines communicating with each other and concurrent processes use this procedure to withdraw

```
(define (withdraw amount)
  (if (>= balance amount)
    (begin (set! balance (- balance amount))
            balance)
    "Insufficient funds"))
```

things can get complicated. This expression `(set! balance (- balance amount))` involves 3 operations (reading `balance`, calculating the new value, and setting the new value). What might happen is that `Paul` attempts to withdraw `10`, he reads `balance` as `100`, then `Peter` attempts to withdraw `25`, he reads `balance` as `100` as well. Many scenarios can heppen. One of them is that `Peter` might succeed to set `balance` in the middle between `Paul`'s read and write operations, then `Paul` sets `balnce` to `90`(assuming that its value is `100` before the withdraw). At this case `Paul` withdraws `10`, `Peter` withdraws `25` and after that the bank has `90` which is a catastrophe for a banking system.

### Correct behavior of concurrent programs

- The problem in the previous example is due to using shared local state in concurrent processes.

- When using assignment in sequential programs we should be careful since the result of evaluating an expression depends on the order of evaluating expressions. For concurrent programs, we might not be able to control such ordering. For this reason, concurrent programs might end up with invalid results if not designed carefully.

- To solve this problem, restrictions should be applied on accessing shared local states by concurrent processes. One rigid requirement is that no more tha one process accessing a shred resource at the same time. One less rigid requirement is that processes accessing shared resources produce results as if they're executing sequentially.

## 3.4.2 Mechanisms for Controlling Concurrency

- Now let's discuss mechanisms that can help us control accessing shared resources in concurrent programs.

### Serializing access to shared state

- **Serialization** is ordering things in a series. Having events `A` & `B` which if executed concurrently leads to issues, using serialization we can make sure that one cannot be executed if the other is being executing. This can be helpful to control access to shared resources. For example to force that reading bank balance can not be run concurrently with writing which eliminates many problems.

- A **serializer**'s responsibility is to maintain a set of procedures such that no 2 procedures of the same set can run concurrently. A serializer is passed a procedure and returns a serialized procedure in its set meaning that the returned procedures won't be running at a time when another procedure of the set is being running.

```
(define s (make-serializer))

(define (increment x) (+ x 1))

(define (serialized-increment) (s increment))
```

- We can use a **serializer** to protect a bank balance withdrawl and deposit happening at the same time from concurrent processes.

```
(define (make-account balance)
  (define (withdraw amount)
    (if (>= balance amount)
        (begin (set! balance (- balance amount))
                balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
     balance)
  (let ((protected (make-serializer)))
    (define (dispatch m)
      (cond ((eq? m ’withdraw) (protected withdraw))
            ((eq? m ’deposit) (protected deposit))
            ((eq? m ’balance) balance)
            (else (error "Unknown request -- MAKE-ACCOUNT" m))))
  dispatch))
```

### Implementing serializers

- Let's implement the serializer in terms of a more primitive construct named a `mutex`. A `mutex` is an object that once `acquired` by a given process, can not be `acquired` by another one until it is `released` by the `acquiring` process.

```
(define (make-serializer)
  (let ((mutex (make-mutex)))
    (lambda (p)
      (define (serialized-p . args)
        (mutex 'acquire)
        (let ((val (apply p args)))
          (mutex 'release)
          val))
      serialized-p)))
```

- Then a `mutex` is a mutable object that maintains a local state of whether being `acquired` or `released`. We will use a one-item list of `true` or `false` to model the `mutex` state. `true` means that the `mutex` is being `acquired` by a process and any process attempting to `acquire` should wait. `false` means that the `mutex` is free to be `acquired`. `release` operation is only setting the one-item list to `false`. `acquire` operation is all about testing whether the one item list is `false` so that we can proceed or `true` so that we can wait.

```
(define (make-mutex)
  (let ((cell (list false)))
    (define (the-mutex m)
      (cond
        ((eq? m 'acquire)
         (if (test-and-set! cell)
             (the-mutex 'acquire))) ;retry
        ((eq? 'release) (clear! cell))))
    the-mutex))

(define (clear! cell)
  (set-car! cell false))

(define (test-and-set! cell)
  (if (car cell)
      true
      (begin (set-car! cell true)
        false)))
```

The reason why we use a one-item list over a boolean variable is that a one-item list is a mutable object that can be passed to `test-and-set!` and `clear!` but a boolean variable is not a mutable object.
